Часть 1
В данной части был произведен EDA, а также некоторые визуализации. Использовались базовые операции вывода, поиск дубликатов/пропущенных значений, их обработка, а также в целом некоторая обработка признаков. Это сделало данные более пригодными для дальнейшего обучения. Использвались также и визуализации для более наглядных выводов о взаимосвязи признаков и целевой переменной. 
Итоги по части 1: 
После всех преобразований получили трейн датасет из 12 колонок и 5840 строк. Дубликаты устранены, пустые значения - тоже. Отказались от колонки torque. Параметры engine и seats приведены к инту (однако в дальнейшем интом оставим только seats, следуя заданиям). 
Наибольшая положительная корреция наблюдается между selling_price и max_power (0.693187). Наименьшую корреляцию видим между столбцами year и engine (0.002819). Также была рассмотрена многомерная связь, когда учитывается боле двух признаков. В данном случае: year, selling_price, transmission. Отмечено, что машины с автоматической коробкой передач растут в цене с очень большим ускорением. 

Часть 2
В данной части я сделала копию с датасетом из только числовых признаков, чтобы обучить модель. 
Исследовалась модель линейнов регрессии (со стандартизацией StandardScaler и без), модель Lasso, а также ElasticNet. 
Для облегчения подбора наилучших параметров был использован GridSearch. 
Итоги: стандартизация не улучшила модель линейной регрессии. В целом все линейные модели дали неудовлитворительный результат на испытаниях (показатели R2 до ~0.594). Стандартизация признаков не дала улучшений метрик. Лучший набор параметров для ElasticNet = {'alpha': 500, 'max_iter': 5000, 'selection': 'cyclic'}. 

Часть 3
Добавление категориальных фич и дальнейшее обучение по такому датасету. 
В этой части мы еще немного поработали с признаками: удалили столбец name и закодировали категориальные фичи (и seats) с помощью OHE. 
В данном задании применили модель Ridge. Она оказалсь наиболее удачной и дала наилучшие показатели метрик: R2=0.641. Делаем выводы, что добавление категориальных признаков значительно улучшает качество обучения. 

Часть 4
В рамках данной части реализована функция business_metric, считающую долю прогнозов, отличающихся от реалиных цен не более чем на 10%. 
Результаты показали, что модель ElasticNet имеею наибольшую долю таких прогнозов (0.244 против 0.24 для Ridge). Такие данные не соответствуют ожиданиям, поскольку для Elastic были самые плохие метрики MSE и R2, а для Ridge - напротив, самые удачные. 

Часть 5
Я сохранила модель со стандартизированными параметрами в формате .pickle для дальнейшего использования в реализации streamlit-приложения. 
Для демонстрации данных в приложении была выбрана модель Ridge. Хоть модель и не показала лучшие результаты в отработке функции предыдущей части, было решено опираться на качество по метрикам, заданным с самого начала задания (MSE, R2). 

Проблемы в 5 части:
При построении приложения на streamlit и, в частности, реализации вывода основных метрик моделей, столкнулась с проблемой: данные для Ridge оказались очень плохими: отрицательный R2. Это являлось не только плохим показателем, но и расходилось с тем, что я получала при обучении модели в задании в ноутбуке. 
Самостоятельная перепроверка дз натолкнула на мысль, что это из-за особенности постройки самого датасета - мы сначала стандартизировали вещественные признаки, а потом обработали присоединенные категориальные. Тем временем, в app.py я писала код подобно тому, который был в обучающем ноутбуке по streamlit, т.е формат там был отличный от того, на котором обучалась модель изначально в ноутбуке с дз. После исследования проблемы (и streamlit-а) поняла как описать данные в коде так, чтобы они были такими же, как у ноутбуке в дз.
Другая проблема: заметила, что все EDA предтавлены на датасете ДО обработки, что не имело смысла. Решением стало написание отдельной функции, в итоге датасет используется в двух вариантах - для EDA и для оценки качества обучения модели. 

Общие выводы: 
Исследовав датасет и приведя его к пригодному для обучения виду, попробовали два варианта: обучение на только числовых признаках, а также добавление категориальных. 
Результаты показали, что модель с добавленными категориальными признаками является более успешной и имеет наилучшие метрики. Однако результат отработки функции business_metric показал, что на этой модели попадание не самое лучше. Это может говорить о недостаточной стабильности модели.


Про приложение streamlit:
Приложение первым шагом просит загрузит csv файл. Ожидается, что в нее будет загружен тестовый датасет (на этом и проверялось). 
В .pickle файле содержатся параметры скейлинга, однако не все. Там scaler_all - это StandardScaler для вещественных признаков. В модели мы храним гиперпараметры и веса для них, а также список признаков. 
Поскольку изначально все приготовления данных делались вручную, то они были перенесены в prepare_features. Может быть, есть способ поместить это в пайплайн .pickle, но я не смогла разобраться. ((
В файле присутствуют две функции обработки: одна обрабатывает датасет для демонстрации EDA, другая - для демонстрации работы модели. Отличие по сути в том, что в первой функции мы не удаляем таргет, а во второй - да. 

В выводе интерфейса представлена основная информация по результатам обучения модели: 
- Первые 5 строк датасета, а также прогноз модели для первых 5 строк (для сравнения);
- Значения основных метрик R2 и MSE для рассматриваемой модели;
- Веса модели;

А также графики: 
- Матрица попарных корреляций признаков (с последующим выводом самой сильной корреляции и самой слабой)
- Визуализация попарных распределений числовых признаков.